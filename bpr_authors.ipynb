{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430449e8-16c6-45c5-a6bd-96f7b52f596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b275ec-e33d-424a-a35a-755ac70bcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn import LGConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcc2508-cbc4-45e4-b0e3-4dd4e7d20449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21732/772045582.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines=\"skip\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('BX-Book-Ratings.csv', sep=';', encoding='latin-1')\n",
    "users = pd.read_csv('BX-Users.csv', sep=';', encoding='latin-1')\n",
    "books = pd.read_csv('BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines=\"skip\")\n",
    "authors = pd.read_csv('BX-authors.csv')\n",
    "\n",
    "# Preprocessing\n",
    "df = df.loc[df['ISBN'].isin(books['ISBN'].unique()) & df['User-ID'].isin(users['User-ID'].unique())]\n",
    "\n",
    "\n",
    "# Keep the 100k highest ratings\n",
    "df = df[df['Book-Rating'] >= 8].iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082da0a2-f394-4a1a-a8cf-bc2fa686745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, authors[['ISBN', 'Book-Author-ID']], on='ISBN', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6885cb-6f90-4911-ba66-fd2de409039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "# user_mapping = {userid: i for i, userid in enumerate(sampled_df['User-ID'].unique())}\n",
    "# item_mapping = {isbn: i for i, isbn in enumerate(sampled_df['ISBN'].unique())}\n",
    "user_mapping = {userid: i for i, userid in enumerate(df['User-ID'].unique())}\n",
    "item_mapping = {isbn: i for i, isbn in enumerate(df['ISBN'].unique())}\n",
    "author_mapping = {authorid: i for i, authorid in enumerate(df['Book-Author-ID'].unique())}\n",
    "\n",
    "# Count users and items\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "num_authors = len(author_mapping)\n",
    "num_total = num_users + num_items + num_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c0f74d-e081-4c7f-a3dd-344d275123b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the adjacency matrix based on user ratings\n",
    "user_ids = torch.LongTensor([user_mapping[i] for i in df['User-ID']])\n",
    "item_ids = torch.LongTensor([item_mapping[i] for i in df['ISBN']])\n",
    "author_ids = torch.LongTensor([author_mapping[i] for i in df['Book-Author-ID']])\n",
    "\n",
    "# edge_index = torch.stack((user_ids, item_ids, author_ids))\n",
    "# Assuming user_ids, item_ids, and author_ids are defined as in your snippet\n",
    "\n",
    "user_item_edges = torch.stack((user_ids, item_ids))  # 2xN tensor for user-item edges\n",
    "item_author_edges = torch.stack((item_ids, author_ids))  # 2xM tensor for item-author edges\n",
    "\n",
    "edge_index = torch.cat((user_item_edges, item_author_edges), dim=1)  # 2x(N+M) tensor for all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2063f8be-af7e-41ee-ac74-a5b990bf28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = train_test_split(range(len(df)), test_size=0.2, random_state=0)\n",
    "val_index, test_index = train_test_split(test_index, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "train_edge_index = edge_index[:, train_index]\n",
    "val_edge_index = edge_index[:, val_index]\n",
    "test_edge_index = edge_index[:, test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "215b31e3-3482-4f89-b3c5-c04f779278f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mini_batch(edge_index):\n",
    "    # Generate BATCH_SIZE random indices\n",
    "    index = np.random.choice(range(edge_index.shape[1]), size=BATCH_SIZE)\n",
    "\n",
    "    # Generate negative sample indices\n",
    "    # It should still return user-positive_item-negative_item triples for user-item interactions\n",
    "    edge_index_neg = structured_negative_sampling(edge_index)\n",
    "    edge_index_neg = torch.stack(edge_index_neg, dim=0)\n",
    "\n",
    "    user_index = edge_index_neg[0, index]  # Users involved in the sampled interactions\n",
    "    pos_item_index = edge_index_neg[1, index]  # Positive items for the sampled interactions\n",
    "    neg_item_index = edge_index_neg[2, index]  # Negative items for the sampled interactions\n",
    "\n",
    "    return user_index, pos_item_index, neg_item_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58a374c-9bf0-4af9-a2a4-9bcbc575e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_authors, num_layers=4, dim_h=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_authors = num_authors\n",
    "        self.num_layers = num_layers\n",
    "        self.emb_users = nn.Embedding(num_embeddings=self.num_users, embedding_dim=dim_h)\n",
    "        self.emb_items = nn.Embedding(num_embeddings=self.num_items, embedding_dim=dim_h)\n",
    "        self.emb_authors = nn.Embedding(num_embeddings=self.num_authors, embedding_dim=dim_h)  # New embedding layer for authors\n",
    "\n",
    "        self.convs = nn.ModuleList(LGConv() for _ in range(num_layers))\n",
    "\n",
    "        nn.init.normal_(self.emb_users.weight, std=0.01)\n",
    "        nn.init.normal_(self.emb_items.weight, std=0.01)\n",
    "        nn.init.normal_(self.emb_authors.weight, std=0.01)  # Initialize author embeddings\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        emb = torch.cat([self.emb_users.weight, self.emb_items.weight, self.emb_authors.weight])  # Include author embeddings\n",
    "        embs = [emb]\n",
    "\n",
    "        for conv in self.convs:\n",
    "            emb = conv(x=emb, edge_index=edge_index)\n",
    "            embs.append(emb)\n",
    "\n",
    "        emb_final = 1/(self.num_layers+1) * torch.mean(torch.stack(embs, dim=1), dim=1)\n",
    "\n",
    "        emb_users_final, emb_items_final, emb_authors_final = torch.split(emb_final, [self.num_users, self.num_items, self.num_authors])  # Split embeddings for users, items, and authors\n",
    "\n",
    "        return emb_users_final, self.emb_users.weight, emb_items_final, self.emb_items.weight, emb_authors_final, self.emb_authors.weight  # Return author embeddings as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a449c928-83fd-48a1-ae1e-f86ccb7e66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items, margin=1.0, pos_weights=None):\n",
    "    reg_loss = LAMBDA * (emb_users.norm().pow(2) +\n",
    "                         emb_pos_items.norm().pow(2) +\n",
    "                         emb_neg_items.norm().pow(2))\n",
    "\n",
    "    pos_ratings = torch.mul(emb_users_final, emb_pos_items_final).sum(dim=-1)\n",
    "    neg_ratings = torch.mul(emb_users_final, emb_neg_items_final).sum(dim=-1)\n",
    "\n",
    "    # Introduce a margin\n",
    "    basic_loss = pos_ratings - neg_ratings - margin\n",
    "\n",
    "    # Apply weighting for positive samples if provided\n",
    "    if pos_weights is not None:\n",
    "        weighted_loss = basic_loss * pos_weights\n",
    "    else:\n",
    "        weighted_loss = basic_loss\n",
    "\n",
    "    bpr_loss = torch.mean(torch.nn.functional.softplus(weighted_loss))\n",
    "\n",
    "    return -bpr_loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "606e4d79-c035-488a-aaf9-0715d508468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_items(edge_index):\n",
    "    user_items = dict()\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_items:\n",
    "            user_items[user] = []\n",
    "        user_items[user].append(item)\n",
    "    return user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4577fe4e-c20e-4fda-b7a9-eda88f0def8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(items_ground_truth, items_predicted):\n",
    "    num_correct_pred = np.sum(items_predicted, axis=1)\n",
    "    num_total_pred = np.array([len(items_ground_truth[i]) for i in range(len(items_ground_truth))])\n",
    "\n",
    "    recall = np.mean(num_correct_pred / num_total_pred)\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0ba098-4242-42f5-b985-ed4498601a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndcg_at_k(items_ground_truth, items_predicted):\n",
    "    test_matrix = np.zeros((len(items_predicted), K))\n",
    "\n",
    "    for i, items in enumerate(items_ground_truth):\n",
    "        length = min(len(items), K)\n",
    "        test_matrix[i, :length] = 1\n",
    "\n",
    "    max_r = test_matrix\n",
    "    idcg = np.sum(max_r * 1. / np.log2(np.arange(2, K + 2)), axis=1)\n",
    "    dcg = items_predicted * (1. / np.log2(np.arange(2, K + 2)))\n",
    "    dcg = np.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[np.isnan(ndcg)] = 0.\n",
    "\n",
    "    return np.mean(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa0bc5a-3af1-438d-aecb-254ecaa5a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, edge_index, exclude_edge_indices):\n",
    "\n",
    "    ratings = torch.matmul(model.emb_users.weight, model.emb_items.weight.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        user_pos_items = get_user_items(exclude_edge_index)\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "        ratings[exclude_users, exclude_items] = -1024\n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(ratings, k=K)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    items_predicted = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        items_predicted.append(label)\n",
    "\n",
    "    recall = compute_recall_at_k(test_user_pos_items_list, items_predicted)\n",
    "    ndcg = compute_ndcg_at_k(test_user_pos_items_list, items_predicted)\n",
    "\n",
    "    return recall, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aa7991a-543a-4cb5-bc28-c561f1964338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def test(model, edge_index, exclude_edge_indices):\n",
    "    # Using '_' for unused author embeddings\n",
    "    emb_users_final, emb_users, emb_items_final, emb_items, _, _ = model.forward(edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
    "\n",
    "    emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n",
    "    emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n",
    "    emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n",
    "\n",
    "\n",
    "    loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items).item()\n",
    "\n",
    "    recall, ndcg = get_metrics(model, edge_index, exclude_edge_indices)\n",
    "\n",
    "    return loss, recall, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6f82914-b000-4b87-8383-da63f79de13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20\n",
    "LAMBDA = 1e-6\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28a0ed68-8d3c-437a-add6-86b01f425584",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LightGCN(num_users, num_items, num_authors)\n",
    "model = model.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7c198ff-a8c5-4e4b-875a-23aee291d73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss: -0.31333 | Val loss: -0.31293 | Val recall@20: 0.00653 | Val ndcg@20: 0.00408\n",
      "Epoch 5 | Train loss: -0.32512 | Val loss: -0.27301 | Val recall@20: 0.01489 | Val ndcg@20: 0.00747\n",
      "Epoch 10 | Train loss: -0.49774 | Val loss: -0.07128 | Val recall@20: 0.01460 | Val ndcg@20: 0.00775\n",
      "Epoch 15 | Train loss: -0.99398 | Val loss: 0.34665 | Val recall@20: 0.01760 | Val ndcg@20: 0.00855\n",
      "Epoch 20 | Train loss: -1.82348 | Val loss: 0.91118 | Val recall@20: 0.01835 | Val ndcg@20: 0.00903\n",
      "Epoch 25 | Train loss: -2.48324 | Val loss: 1.58961 | Val recall@20: 0.01807 | Val ndcg@20: 0.00879\n",
      "Epoch 30 | Train loss: -3.53394 | Val loss: 2.36438 | Val recall@20: 0.01765 | Val ndcg@20: 0.00869\n",
      "Epoch 35 | Train loss: -5.42285 | Val loss: 3.23769 | Val recall@20: 0.01757 | Val ndcg@20: 0.00891\n",
      "Epoch 40 | Train loss: -6.87920 | Val loss: 4.21863 | Val recall@20: 0.01765 | Val ndcg@20: 0.00905\n",
      "Epoch 45 | Train loss: -8.71951 | Val loss: 5.28722 | Val recall@20: 0.01765 | Val ndcg@20: 0.00905\n",
      "Epoch 50 | Train loss: -8.70656 | Val loss: 6.44953 | Val recall@20: 0.01760 | Val ndcg@20: 0.00873\n",
      "CPU times: user 4h 16min 37s, sys: 10min 13s, total: 4h 26min 51s\n",
      "Wall time: 2h 55min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_batch = int(len(train_index)/BATCH_SIZE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    for _ in range(n_batch):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use train_edge_index for the forward pass during training\n",
    "        emb_users_final, emb_users, emb_items_final, emb_items, emb_authors_final, emb_authors = model.forward(train_edge_index)\n",
    "\n",
    "        user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(train_edge_index)\n",
    "\n",
    "        emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n",
    "        emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n",
    "        emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n",
    "\n",
    "        train_loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, ndcg = test(model, val_edge_index, [train_edge_index])\n",
    "        print(f\"Epoch {epoch} | Train loss: {train_loss.item():.5f} | Val loss: {val_loss:.5f} | Val recall@{K}: {recall:.5f} | Val ndcg@{K}: {ndcg:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eb9d2a2-77ec-41bb-8e84-9946ead44ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.37681 | Test recall@20: 0.01689 | Test ndcg@20: 0.00827\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_recall, test_ndcg = test(model, test_edge_index.to(device), [train_edge_index, val_edge_index])\n",
    "\n",
    "print(f\"Test loss: {test_loss:.5f} | Test recall@{K}: {test_recall:.5f} | Test ndcg@{K}: {test_ndcg:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14e6ef-90c9-4a33-8ca0-665d0b13a5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
